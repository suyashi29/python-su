{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b01fbb",
   "metadata": {},
   "source": [
    "\n",
    "### Types of GANs\n",
    "\n",
    "| **GAN Type**               | **Key Idea**                                                 | **Objective / Loss Formula**                                                                                | **Strengths**                                                  | **Limitations**                                          | **Typical Use Cases**                                          |                       |                                                      |\n",
    "| -------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------------- | --------------------- | ---------------------------------------------------- |\n",
    "| **Vanilla GAN**            | Adversarial game between Generator (G) and Discriminator (D) | (\\min_G \\max_D V(D,G) = \\mathbb{E}*{x\\sim p*{data}}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z}[\\log(1 - D(G(z)))]) | Simple, foundational, easy to implement                        | Training instability, mode collapse, vanishing gradients | Academic learning, toy datasets (MNIST), GAN fundamentals      |                       |                                                      |\n",
    "| **DCGAN**                  | CNN-based GAN with architectural constraints                 | Same as Vanilla GAN (cross-entropy loss)                                                                    | Stable training, good image quality, scalable to larger images | Still sensitive to hyperparameters                       | Image generation (faces, objects), representation learning     |                       |                                                      |\n",
    "| **Conditional GAN (cGAN)** | GAN conditioned on labels or attributes                      | (\\min_G \\max_D \\mathbb{E}[\\log D(x                                                                          | y)] + \\mathbb{E}[\\log(1 - D(G(z                                | y)))])                                                   | Controlled generation, class-specific outputs                  | Requires labeled data | Image-to-image translation, class-specific synthesis |\n",
    "| **WGAN**                   | Uses Wasserstein (Earth-Mover) distance                      | (\\min_G \\max_{D\\in\\mathcal{D}} \\mathbb{E}[D(x)] - \\mathbb{E}[D(G(z))])                                      | Stable gradients, reduced mode collapse                        | Weight clipping harms capacity                           | High-quality image synthesis, stable GAN training              |                       |                                                      |\n",
    "| **WGAN-GP**                | Gradient penalty instead of weight clipping                  | (\\mathbb{E}[D(G(z))] - \\mathbb{E}[D(x)] + \\lambda \\mathbb{E}[(|\\nabla_{\\hat{x}} D(\\hat{x})|_2 - 1)^2])      | Very stable, best convergence properties                       | Higher computation cost                                  | Production-grade image generation, medical & satellite imagery |                       |                                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeee955",
   "metadata": {},
   "source": [
    "\n",
    "# GANs with Full Training Pipelines and Visualization\n",
    "\n",
    "This notebook provides:\n",
    "- Conceptual explanation of GANs\n",
    "- Five common GAN variants\n",
    "- End-to-end **training loops**\n",
    "- **Image visualization outputs**\n",
    "\n",
    "Dataset used: **MNIST** (simple, fast, standard for GAN demos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b26e24",
   "metadata": {},
   "source": [
    "\n",
    "## Common Imports and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST\n",
    "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 127.5 - 1.0\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5  # kept small for demo\n",
    "LATENT_DIM = 100\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e0c67",
   "metadata": {},
   "source": [
    "\n",
    "## Helper: Image Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_generated_images(generator, epoch, latent_dim=100):\n",
    "    noise = tf.random.normal([16, latent_dim])\n",
    "    images = generator(noise, training=False)\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(images[i].numpy().reshape(28,28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Epoch {epoch}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0816d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Vanilla GAN – Full Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator():\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=(LATENT_DIM,)),\n",
    "        layers.Dense(784, activation='tanh')\n",
    "    ])\n",
    "\n",
    "def build_discriminator():\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=(784,)),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "g_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "d_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    noise = tf.random.normal([real_images.shape[0], LATENT_DIM])\n",
    "\n",
    "    with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "        d_loss = loss_fn(tf.ones_like(real_output), real_output) +                  loss_fn(tf.zeros_like(fake_output), fake_output)\n",
    "\n",
    "        g_loss = loss_fn(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "\n",
    "    d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "    g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "\n",
    "    return d_loss, g_loss\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    for batch in dataset:\n",
    "        d_loss, g_loss = train_step(batch)\n",
    "\n",
    "    print(f\"Epoch {epoch}, D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\")\n",
    "    plot_generated_images(generator, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059da9eb",
   "metadata": {},
   "source": [
    "\n",
    "## 2. DCGAN – Architecture & Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8330a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dcgan_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(7*7*128, activation='relu', input_shape=(LATENT_DIM,)),\n",
    "        layers.Reshape((7,7,128)),\n",
    "        layers.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n",
    "        layers.Conv2DTranspose(1, 4, strides=2, padding='same', activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_dcgan_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28,28,1)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfdc10",
   "metadata": {},
   "source": [
    "\n",
    "## Note on Other GAN Types\n",
    "To keep runtime reasonable, **cGAN, WGAN, and WGAN-GP** follow the same training pattern with:\n",
    "- Modified loss functions\n",
    "- Label conditioning (cGAN)\n",
    "- Critic + Wasserstein loss (WGAN)\n",
    "- Gradient penalty (WGAN-GP)\n",
    "\n",
    "These patterns are included earlier conceptually and can be extended using this training loop template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04bae3",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "| GAN Type | Training Stability | Control | Use Case |\n",
    "|--------|------------------|--------|---------|\n",
    "| Vanilla GAN | Low | No | Learning |\n",
    "| DCGAN | Medium | No | Image generation |\n",
    "| cGAN | Medium | Yes | Conditional synthesis |\n",
    "| WGAN | High | No | Stable training |\n",
    "| WGAN-GP | Very High | No | Production systems |\n",
    "\n",
    "### Architect Takeaway\n",
    "- **Vanilla GAN** → teaching & demos  \n",
    "- **DCGAN** → standard image GAN  \n",
    "- **WGAN-GP** → enterprise-grade stability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
